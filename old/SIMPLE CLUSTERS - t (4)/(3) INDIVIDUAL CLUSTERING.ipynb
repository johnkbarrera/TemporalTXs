{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDIVIDUAL CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detalles"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para cada cliente que tiene  S'=< U(1),U(2),...,U(m)>  con m<=n\n",
    "\n",
    "Entrada      Entrada S'\n",
    "             Salida F = {f1,f2,...,fo}    con o<=m\n",
    "\n",
    "    Procesamos los footprints (U)\n",
    "        para i de 1 a u-longitud         \n",
    "            Usando \"MiniBatchKMeans\" obtenemos la inercia\n",
    "                    k = [1,2,3,...,u-longitud]\n",
    "              inercia = [?,?,?,...,?]\n",
    "        salida: s1:{k,inercia}\n",
    "  \n",
    "    Mejor k\n",
    "        Generamos 1000 puntos con el comportamiento de s1 con la funcion \"UnivariateSpline\"\n",
    "        donde tenemos k',inercia'\n",
    "            \n",
    "         salida: s_final = OBTENER_PUNTO(k',inercia')           # MEJOR K\n",
    "         \n",
    "            \n",
    "                    \n",
    "_________________________________________________________________________________________            \n",
    "_________________________________________________________________________________________\n",
    "\n",
    "DEFINIMOS \"OBTENER_PUNTO\"\n",
    "|\n",
    "|  Entrada: x,y (vector)               # los puntos interpolados\n",
    "| \n",
    "|  PARA i de o a length(x ó y)\n",
    "|   |  C = PUNTO_MAS_CERCANO(A={xo,yo}, B={xf,yf}, X={xi,yi})      C = {c1, c2}\n",
    "|   |  d = raiz_2[ (c1-xi)^2 + (c2-yi)^2 ]\n",
    "|   |  SI d > max_d\n",
    "|   |   |  max_d = d\n",
    "|   |   |  index = 1\n",
    "|   |  FIN\n",
    "|  FIN\n",
    "|  \n",
    "|  Salida: index\n",
    "|  \n",
    "FIN     \n",
    "_________________________________________________________________________________________\n",
    "\n",
    "DEFINIMOS \"PUNTO_MAS_CERCANO\"\n",
    "|\n",
    "|  Entrada: A={xo,yo}, B={xf,yf}, X={xi,yi} (listas)               # los puntos interpolados\n",
    "|  \n",
    "|  delta_x = xf - xo\n",
    "|  delta_y = yf - yo\n",
    "|\n",
    "|  SI delta_x y delta_y == 0\n",
    "|  |   Salida = X\n",
    "|  FIN\n",
    "| \n",
    "|  U = [(xi-x0) * delta_y] + [(yi-yo) * delta_x]  / ( delta_x ^ 2 + delta_y ^ 2 )\n",
    "|\n",
    "|  SI U < 0\n",
    "|  |  Salida = A      \n",
    "|  SINO_SI U > 1\n",
    "|  |  Salida = B      \n",
    "|  SINO\n",
    "|  |  cp_x = xo + u * delta_x\n",
    "|  |  cp_y = yo + u * delta_y\n",
    "|  |  Salida = { cp_x , cp_y }\n",
    "|  FIN\n",
    "FIN   \n",
    "____________________________________________________________________________________________ \n",
    "____________________________________________________________________________________________   \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista de Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos la lista de clientes sin repetir\n",
    "\n",
    "def leer_data():\n",
    "    outfile='./data/data.csv'\n",
    "    data = pd.read_csv(outfile)\n",
    "    return data\n",
    "\n",
    "data = leer_data()\n",
    "clientes =  data.groupby('client_id').client_id.count().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal TXs footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la ruta de los archivos \n",
    "\n",
    "file='U'\n",
    "raw_data='./data/%s.json' %(file)\n",
    "individual_footprint=\"%s.individual_footprint\" %(raw_data)\n",
    "individual_clusters=\"%s.clusters\" %(individual_footprint)\n",
    "individual_labels=\"%s.labels\" %(individual_footprint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_footprint(data,tests,log=False):\n",
    "    from sklearn.cluster import MiniBatchKMeans\n",
    "    #KMeans(init='k-means++', n_clusters=k, n_init=10)\n",
    "    import datetime\n",
    "    K={}\n",
    "    for k in tests:\n",
    "        if k<=len(data):\n",
    "            if log:\n",
    "                print(\"%s: processing %s\"%(datetime.datetime.now(),k))\n",
    "            K[k]=bench_k_means(MiniBatchKMeans(init='k-means++', n_clusters=k, batch_size=100,\n",
    "                      n_init=10, max_no_improvement=10, verbose=0,\n",
    "                      random_state=0),name=\"k-means++\", data=data)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_best_k(x,y,occurrencies, plot=False,points=1000,sf=0.9):\n",
    "    import numpy as np\n",
    "    \n",
    "    if len(x)<5:\n",
    "        return max(1, round(np.sqrt(occurrencies/2)))\n",
    "    \n",
    "    from scipy.interpolate import interp1d\n",
    "    from scipy.interpolate import UnivariateSpline\n",
    "    spl = UnivariateSpline(x, y)\n",
    "    spl.set_smoothing_factor(sf)\n",
    "    xs = np.linspace(min(x), max(x), points)\n",
    "    ys = spl(xs)\n",
    "    idx_better_k=get_change_point(xs, ys)\n",
    "    if plot:\n",
    "        import pylab\n",
    "        pylab.plot(xs,ys)\n",
    "        \n",
    "        pylab.scatter(xs[idx_better_k],ys[idx_better_k],s=20, marker='o')\n",
    "        pylab.text(xs[idx_better_k],ys[idx_better_k],\"bestK %s\" %(np.round(xs[idx_better_k])))\n",
    "        return int(np.round(xs[idx_better_k])),pylab\n",
    "    return int(np.round(xs[idx_better_k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_k_means(estimator, name, data,distance_function=None):\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    if distance_function:\n",
    "        estimator.fit(data,distance_function)\n",
    "    else:\n",
    "        estimator.fit(data)\n",
    "    #cluster_labels = estimator.fit_predict(data)\n",
    "    #silhouette_score_ = silhouette_score(data, cluster_labels)\n",
    "    \n",
    "    inertia=estimator.inertia_\n",
    "    duration=time.time() - t0\n",
    "    return {'inertia':inertia,'duration':duration, 'estimator':estimator}#,'silhouette':silhouette_score_}\n",
    "\n",
    "def get_change_point(x, y):\n",
    "    \"\"\"\n",
    "         Elección del mejor K\n",
    "         :: param x: lista de valores de K\n",
    "         :: param y: lista de valores de SSE\n",
    "    \"\"\"\n",
    "    import math\n",
    "    max_d = -float('infinity')\n",
    "    index = 0\n",
    "\n",
    "    for i in range(0, len(x)):\n",
    "        c = closest_point_on_segment(a=[x[0], y[0]], b=[x[len(x)-1], y[len(y)-1]], p=[x[i], y[i]])\n",
    "        d = math.sqrt((c[0]-x[i])**2 + (c[1]-y[i])**2)\n",
    "        if d > max_d:\n",
    "            max_d = d\n",
    "            index = i\n",
    "    \n",
    "    return index\n",
    "\n",
    "def closest_point_on_segment(a, b, p):\n",
    "    sx1 = a[0]\n",
    "    sx2 = b[0]\n",
    "    sy1 = a[1]\n",
    "    sy2 = b[1]\n",
    "    px = p[0]\n",
    "    py = p[1]\n",
    "\n",
    "    x_delta = sx2 - sx1\n",
    "    y_delta = sy2 - sy1\n",
    "\n",
    "    if x_delta == 0 and y_delta == 0:\n",
    "        return p\n",
    "\n",
    "    u = ((px - sx1) * x_delta + (py - sy1) * y_delta) / (x_delta * x_delta + y_delta *  y_delta)\n",
    "    if u < 0:\n",
    "        closest_point = a\n",
    "    elif u > 1:\n",
    "        closest_point = b\n",
    "    else:\n",
    "        cp_x = sx1 + u * x_delta\n",
    "        cp_y = sy1 + u * y_delta\n",
    "        closest_point = [cp_x, cp_y]\n",
    "\n",
    "    return closest_point\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Clustering"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Debe hacerce para cada cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkn/anaconda3/lib/python3.6/site-packages/scipy/interpolate/fitpack2.py:226: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "227662"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de filas del archivo\n",
    "f=open(individual_footprint)\n",
    "num_rows = len(f.readlines())-1\n",
    "f.close()\n",
    "\n",
    "#<customer_id;year;week;profile_id;size;t1... tn >\n",
    "import datetime\n",
    "f=open(individual_footprint)\n",
    "fw=open(individual_clusters,'w')  #uid,cluster_id,centroid\n",
    "fw2=open(individual_labels,'w') #uid,year,week,cluster_id,profile\n",
    "fw.write('customer_tag;individual_cluster;d0t0;d1t0;d2t0;d3t0;d4t0;d5t0;d6t0;d0t1;d1t1;d2t1;d3t1;d4t1;d5t1;d6t1;d0t2;d1t2;d2t2;d3t2;d4t2;d5t2;d6t2;d0t3;d1t3;d2t3;d3t3;d4t3;d5t3;d6t3\\n')\n",
    "fw2.write('customer_tag;year;week;individual_cluster;d0t0;d1t0;d2t0;d3t0;d4t0;d5t0;d6t0;d0t1;d1t1;d2t1;d3t1;d4t1;d5t1;d6t1;d0t2;d1t2;d2t2;d3t2;d4t2;d5t2;d6t2;d0t3;d1t3;d2t3;d3t3;d4t3;d5t3;d6t3\\n')\n",
    "\n",
    "f.readline()\n",
    "data=[] #buffer\n",
    "\n",
    "footprints_clustered=0\n",
    "footprints_clusters=0\n",
    "n_cliente=0\n",
    "contador = 0\n",
    "temporal= 0\n",
    "for row in f: #reading individual footprint\n",
    "    row=row.strip().split(',') # leemos cada elemento da linea parseada por \",\"\n",
    "    uid=row[0]\n",
    "    year=row[1]\n",
    "    week=row[2]\n",
    "    size=float(row[5])\n",
    "    profile=np.array([float(el) for el in row[6:]])\n",
    "    # Individual clustering\n",
    "    if uid==clientes[n_cliente]: # Para cada fila donde los \"uid\" son iguales \n",
    "        data.append(((uid,year,week),profile))     \n",
    "        contador+=1\n",
    "    else: #final de cliente\n",
    "        \n",
    "        #---------------------------------------------------------------------\n",
    "        # procesar data\n",
    "        #---------------------------------------------------------------------\n",
    "        to_cluster=[el[1] for el in data]\n",
    "        K=process_footprint(to_cluster,np.arange(1,len(to_cluster)+1))\n",
    "\n",
    "        # choose k\n",
    "        x=list(K.keys())\n",
    "        y=[K[k]['inertia'] for k in K]\n",
    "        best_k=compute_best_k(x,y,len(to_cluster))\n",
    "        ###print(str(contador)+' => clustering: '+str(clientes[n_cliente])+' len data: '+str(len(data))+\" best k: \"+str(best_k))\n",
    "        \n",
    "        # clustering\n",
    "        if best_k==1:\n",
    "            #to few records\n",
    "            cluster_centers_=[np.average(to_cluster,axis=0)]\n",
    "            labels_=[0]*len(to_cluster)  \n",
    "        else:\n",
    "            cluster_centers_=K[best_k]['estimator'].cluster_centers_\n",
    "            labels_=K[best_k]['estimator'].labels_\n",
    "        \n",
    "        #export individual centroids\n",
    "        for i in np.arange(len(cluster_centers_)):\n",
    "            string=\"%s;%s;%s\\n\"%(clientes[n_cliente],i,';'.join([str(el) for el in cluster_centers_[i]])) #uid,cluster_id,centroid\n",
    "            fw.write(string)\n",
    "            footprints_clusters+=1\n",
    "        fw.flush()\n",
    "\n",
    "        #export original data and labels\n",
    "        for i in np.arange(len(data)):\n",
    "            uid2=data[i][0]\n",
    "            profile2=data[i][1]\n",
    "            label2=labels_[i]\n",
    "            string=\"%s;%s;%s;%s;%s\\n\" %(uid2[0],uid2[1],uid2[2],label2\n",
    "                                                    ,';'.join([str(el) for el in profile2]))#uid,year,week,cluster_id,profile\n",
    "            fw2.write(string)\n",
    "            footprints_clustered+=1\n",
    "        fw2.flush()\n",
    "        #---------------------------------------------------------------------\n",
    "        #---------------------------------------------------------------------\n",
    "        \n",
    "        \n",
    "\n",
    "        data=[] #buffer\n",
    "        data.append(((uid,year,week),profile))\n",
    "        \n",
    "        contador+=1\n",
    "        temporal+=1\n",
    "        n_cliente+=1\n",
    "        \n",
    "    if contador == num_rows:        # Para el ultimo cliente y ultima fila\n",
    "        #---------------------------------------------------------------------\n",
    "        # procesar data\n",
    "        #---------------------------------------------------------------------\n",
    "        to_cluster=[el[1] for el in data]\n",
    "        K=process_footprint(to_cluster,np.arange(1,len(to_cluster)+1))\n",
    "\n",
    "        # choose k\n",
    "        x=list(K.keys())\n",
    "        y=[K[k]['inertia'] for k in K]\n",
    "        best_k=compute_best_k(x,y,len(to_cluster))\n",
    "        ###print(str(contador)+' => clustering: '+str(clientes[n_cliente])+' len data: '+str(len(data))+\" best k: \"+str(best_k))\n",
    "        \n",
    "        # clustering\n",
    "        if best_k==1:\n",
    "            #to few records\n",
    "            cluster_centers_=[np.average(to_cluster,axis=0)]\n",
    "            labels_=[0]*len(to_cluster)  \n",
    "        else:\n",
    "            cluster_centers_=K[best_k]['estimator'].cluster_centers_\n",
    "            labels_=K[best_k]['estimator'].labels_\n",
    "        \n",
    "        #export individual centroids\n",
    "        for i in np.arange(len(cluster_centers_)):\n",
    "            string=\"%s;%s;%s\\n\"%(uid,i,';'.join([str(el) for el in cluster_centers_[i]])) #uid,cluster_id,centroid\n",
    "            fw.write(string)\n",
    "            footprints_clusters+=1\n",
    "        fw.flush()\n",
    "\n",
    "        #export original data and labels\n",
    "        for i in np.arange(len(data)):\n",
    "            uid2=data[i][0]\n",
    "            profile2=data[i][1]\n",
    "            label2=labels_[i]\n",
    "            string=\"%s;%s;%s;%s;%s\\n\" %(uid2[0],uid2[1],uid2[2],label2\n",
    "                                                    ,';'.join([str(el) for el in profile2]))#uid,year,week,cluster_id,profile\n",
    "            fw2.write(string)\n",
    "            footprints_clustered+=1\n",
    "        fw2.flush()\n",
    "        #---------------------------------------------------------------------\n",
    "        #---------------------------------------------------------------------\n",
    "        \n",
    "        print(\"final\")   \n",
    "    \n",
    "    \n",
    "\n",
    "temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
